# Story 1.03: Evidence Classification Service - AI Tier Classifier

## Status
Ready for Review

## Story

**As a** backend developer,
**I want** to create an evidence classification service that uses OpenAI to analyze documents and assign evidence tiers,
**so that** documents can be automatically classified as Tier 0, 1, or 2 based on content characteristics.

## Acceptance Criteria

1. New service file `evidence-classification.service.ts` created extending BaseService
2. Service method `classifyDocument(documentId: string): Promise<ClassificationResult>` implemented
3. Method fetches document content from Replit object storage
4. Method sends document to OpenAI GPT-4 with classification prompt
5. Prompt instructs AI to identify: formal structure, version control indicators, approval workflows, system-generated data markers
6. AI returns: tier (0/1/2), confidence (0-1), reasoning (string explanation)
7. Method saves classification to Document record: evidenceTier, tierConfidenceScore, tierClassificationReason, classifiedAt
8. Method handles OpenAI API errors gracefully: log error, classify as TIER_0, return low confidence
9. Method includes circuit breaker: after 5 consecutive failures, disable classification for 5 minutes
10. Method caches classification results in Redis (key: `evidence_classification:<document_id>`, TTL: 30 days)
11. Unit tests cover: successful classification, API errors, circuit breaker activation, cache hits
12. Integration test: classify real sample documents (policy PDF, CSV log file, email TXT)

## Tasks / Subtasks

- [ ] Create evidence-classification.service.ts extending BaseService (AC: 1)
  - [ ] Import BaseService, PrismaClient, Logger
  - [ ] Import objectStorage for Replit storage access
  - [ ] Import OpenAI client (from existing ai-analysis.service.ts pattern)
  - [ ] Import Redis client for caching
- [ ] Implement classifyDocument method (AC: 2-7)
  - [ ] Fetch document record from database by documentId
  - [ ] Retrieve document content from Replit object storage
  - [ ] Construct classification prompt with tier definitions
  - [ ] Call OpenAI GPT-4 API with prompt + document content (first 5000 chars)
  - [ ] Parse AI response into ClassificationResult { tier, confidence, reason, indicators }
  - [ ] Update Document record with classification fields
  - [ ] Return ClassificationResult
- [ ] Implement error handling and graceful degradation (AC: 8)
  - [ ] Wrap OpenAI call in try-catch
  - [ ] On error: log error with context, classify as TIER_0, set confidence to 0.0
  - [ ] Return degraded result with reason explaining failure
- [ ] Implement circuit breaker pattern (AC: 9)
  - [ ] Track consecutive failure count in memory or Redis
  - [ ] After 5 consecutive failures: set circuit "open" for 5 minutes
  - [ ] When circuit open: skip OpenAI call, return TIER_0 immediately
  - [ ] After 5 minutes: attempt OpenAI call again (circuit "half-open")
  - [ ] On success: reset failure count, close circuit
- [ ] Implement Redis caching (AC: 10)
  - [ ] Before classification: check Redis for cached result
  - [ ] If cache hit: return cached result immediately
  - [ ] After successful classification: cache result with 30-day TTL
  - [ ] Cache invalidation: on document deletion or admin override
- [ ] Write unit tests (AC: 11)
  - [ ] Test successful classification (mock OpenAI response)
  - [ ] Test OpenAI API error (mock error throw)
  - [ ] Test circuit breaker activation after 5 failures
  - [ ] Test cache hit scenario (Redis returns cached result)
  - [ ] Test cache miss scenario (Redis returns null)
- [ ] Write integration test (AC: 12)
  - [ ] Upload sample policy PDF, classify, verify TIER_1 assignment
  - [ ] Upload sample CSV log file, classify, verify TIER_2 assignment
  - [ ] Upload sample email TXT, classify, verify TIER_0 assignment

## Dev Notes

### Relevant Source Tree
- `backend/src/services/evidence-classification.service.ts` - NEW: Create this file
- `backend/src/services/base.service.ts` - Base class to extend
- `backend/src/services/ai-analysis.service.ts` - Existing OpenAI integration pattern
- `backend/src/objectStorage.ts` - Replit storage wrapper
- `backend/src/config/redis.ts` - Redis client configuration

### Service Constructor Pattern (Mandatory)
```typescript
export class EvidenceClassificationService extends BaseService {
  constructor(
    prisma: PrismaClient,
    private aiAnalysisService: AIAnalysisService,
    private redis: RedisClient,
    logger?: Logger
  ) {
    super(prisma, logger)
  }
}
```

### Classification Prompt Design

**Prompt Structure:**
```
You are an expert compliance auditor analyzing documentation quality.

Classify this document into one of three evidence tiers:

TIER_2 (System-Generated):
- Database exports, API logs, system reports
- Automated outputs with timestamps, version numbers
- Machine-generated data with structured format

TIER_1 (Policy Documents):
- Formal policies, procedures, workflows
- Documents with approval signatures, version control
- Official company documentation

TIER_0 (Self-Declared):
- Emails, informal notes, draft documents
- Statements without formal approval process
- Unstructured informal communication

Analyze the following document and respond with JSON:
{
  "tier": "TIER_0" | "TIER_1" | "TIER_2",
  "confidence": 0.0-1.0,
  "reason": "Brief explanation of classification rationale",
  "indicators": {
    "hasTimestamps": boolean,
    "hasVersionControl": boolean,
    "hasApprovalSignatures": boolean,
    "isStructuredData": boolean
  }
}

Document content:
{document_content}
```

### Graceful Degradation Strategy

**Never Throw Errors:**
This service must never throw exceptions that break assessment flow. All errors result in TIER_0 classification with explanation.

**Error Response Format:**
```typescript
{
  tier: EvidenceTier.TIER_0,
  confidence: 0.0,
  reason: 'Classification failed - defaulting to self-declared tier. Error: [error message]',
  indicators: {}
}
```

### OpenAI Integration

**Reuse Existing Pattern:**
Study `ai-analysis.service.ts` for OpenAI client setup, error handling, token limits.

**Token Optimization:**
- Limit document content to first 5000 characters
- Use GPT-4 for accuracy (not GPT-3.5)
- Max response tokens: 500
- Temperature: 0.2 (deterministic)

**Retry Logic (from Architecture Coding Standards):**
```typescript
if (error.status === 429 && retryCount < 3) {
  await delay(1000 * Math.pow(2, retryCount))
  return this.classifyEvidenceTier(content, retryCount + 1)
}
```

### Redis Cache Strategy

**Key Pattern:** `evidence_classification:<document_id>`
**TTL:** 30 days (2592000 seconds)
**Value Format:** JSON string of ClassificationResult

**Cache Invalidation Events:**
- Document deleted: invalidate immediately
- Admin overrides classification: invalidate and update with new values
- Never invalidate automatically (30-day TTL sufficient)

### Integration Points

**Existing Services:**
- `document.service.ts` - Triggers classification after document upload
- `assessment.service.ts` - Triggers batch classification on assessment completion
- `objectStorage.ts` - Retrieves document content for analysis

**Database Fields (from Story 1.1):**
- Document.evidenceTier (EvidenceTier enum)
- Document.tierConfidenceScore (Float)
- Document.tierClassificationReason (String)
- Document.classifiedAt (DateTime)

### Testing

**Unit Testing:**
Location: `backend/src/services/evidence-classification.service.spec.ts`

Test frameworks: Vitest 3

Mock dependencies:
- OpenAI client responses
- Redis get/set operations
- Prisma document queries
- objectStorage.getObject()

Test cases:
1. Successful classification returns TIER_2 with confidence 0.95
2. OpenAI API error returns TIER_0 with confidence 0.0
3. After 5 consecutive errors, circuit breaker opens
4. Cache hit returns result without OpenAI call
5. Cache miss triggers OpenAI call and caches result

**Integration Testing:**
Location: `backend/tests/integration/evidence-classification.spec.ts`

Test cases:
1. Upload policy PDF → classify → verify TIER_1 assignment
2. Upload CSV log → classify → verify TIER_2 assignment
3. Upload email TXT → classify → verify TIER_0 assignment
4. Real OpenAI API call (use test API key or mock in CI)

**Coverage Target:** ≥80% unit test coverage

## Change Log

| Date       | Version | Description                          | Author        |
|------------|---------|--------------------------------------|---------------|
| 2025-10-07 | 1.0     | Initial story created from PRD Epic 1 | SM (Winston)  |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent during implementation_

### Debug Log References
_To be populated by dev agent during implementation_

### Completion Notes
_To be populated by dev agent during implementation_

### File List
_To be populated by dev agent during implementation_

## QA Results

_To be populated by QA agent after implementation review_
