# Story 1.23: Integration Testing - End-to-End Enhanced Assessment Flow

## Status
Draft

## Story

**As a** QA engineer,
**I want** to create comprehensive integration tests for the full enhanced assessment workflow,
**so that** we verify all components work together correctly from assessment creation to vendor matching.

## Acceptance Criteria

1. **Test Suite: Enhanced Assessment E2E** (`backend/tests/integration/enhanced-assessment-e2e.spec.ts`)
2. **Test Case 1: Assessment Creation with Enhanced Methodology**
   - Create user, organization, assessment template with weights
   - Create assessment with feature flag enabled
   - Verify: assessment.scoringMethodology = "complete"
3. **Test Case 2: Document Upload and Evidence Classification**
   - Upload 3 documents (system log, policy PDF, email text)
   - Trigger classification
   - Verify: documents assigned correct tiers (Tier 2, Tier 1, Tier 0)
   - Verify: classification reasons stored
   - Verify: confidence scores present
4. **Test Case 3: Assessment Execution with Weighted Scoring**
   - Generate answers for assessment questions (simulate AI responses)
   - Set rawQualityScore values on answers
   - Complete assessment
   - Verify: weighted scoring service calculates finalScore with tier multipliers
   - Verify: section scores calculated correctly
   - Verify: overall score calculated correctly (0-100 scale)
   - Verify: risk band assigned (Critical/High/Medium/Low)
5. **Test Case 4: Gap Identification and Prioritization**
   - Verify: questions with finalScore <3.0 flagged as gaps
   - Verify: gaps assigned severity, priority, effort, costRange
   - Verify: priority ranking correct (high priority for foundational questions in high-weight sections)
6. **Test Case 5: Priorities Questionnaire Submission**
   - Submit priorities via POST /assessments/:id/priorities
   - Verify: AssessmentPriorities record created
   - Verify: data validation (rankedPriorities subset of selectedUseCases)
   - Retrieve priorities via GET /assessments/:id/priorities
   - Verify: data matches submission
7. **Test Case 6: Enhanced Vendor Matching**
   - Seed vendor database with 10 test vendors (varied profiles)
   - Request vendor matches via GET /assessments/:id/vendor-matches-v2
   - Verify: vendors scored with base + boost
   - Verify: match reasons generated
   - Verify: vendors sorted by totalScore descending
   - Verify: only vendors with score ≥80 returned
8. **Test Case 7: Strategy Matrix Generation**
   - Request strategy matrix via GET /assessments/:id/strategy-matrix
   - Verify: gaps organized into 3 timeline buckets (immediate/near-term/strategic)
   - Verify: bucket aggregations correct (gap count, effort distribution, cost range)
   - Verify: vendor recommendations per bucket (vendors covering multiple gaps)
9. **Test Case 8: Enhanced Results Retrieval**
   - Request results via GET /assessments/:id/results
   - Verify: response includes all enhanced fields
   - Verify: evidence tier summary present
   - Verify: weighted score breakdown present
   - Verify: strategy matrix summary present
10. **Test Case 9: Feature Flag Disabled Scenario**
    - Create assessment with feature flag disabled
    - Verify: assessment.scoringMethodology = "unavailable"
    - Verify: POST /priorities returns 400 error
    - Verify: GET /vendor-matches-v2 returns 400 error
    - Verify: GET /results excludes enhanced fields
11. **Test Case 10: Legacy Assessment Compatibility**
    - Query existing assessment created before enhanced features
    - Verify: legacy assessment still queryable
    - Verify: legacy results endpoint still works
    - Verify: no data corruption or errors

## Tasks / Subtasks

- [ ] Create E2E test suite file (AC: 1)
  - [ ] Create backend/tests/integration/enhanced-assessment-e2e.spec.ts
  - [ ] Set up test database with clean state before each test
  - [ ] Create test data seeding helpers
- [ ] Implement Test Case 1: Assessment Creation (AC: 2)
  - [ ] Create test user and organization
  - [ ] Create assessment template with weighted sections and questions
  - [ ] Enable feature flag for test
  - [ ] Create assessment via API
  - [ ] Assert scoringMethodology = "complete"
- [ ] Implement Test Case 2: Document Upload and Classification (AC: 3)
  - [ ] Upload 3 test documents (system log, policy PDF, email text)
  - [ ] Trigger evidence classification
  - [ ] Assert documents assigned correct tiers
  - [ ] Assert classification reasons and confidence scores present
- [ ] Implement Test Case 3: Weighted Scoring (AC: 4)
  - [ ] Generate answers with rawQualityScore values
  - [ ] Complete assessment via API
  - [ ] Assert finalScore calculated with tier multipliers
  - [ ] Assert section scores calculated correctly
  - [ ] Assert overall score in 0-100 range
  - [ ] Assert risk band assigned (Critical/High/Medium/Low)
- [ ] Implement Test Case 4: Gap Identification (AC: 5)
  - [ ] Query gaps for completed assessment
  - [ ] Assert questions with finalScore <3.0 flagged as gaps
  - [ ] Assert gaps have severity, priority, effort, costRange
  - [ ] Assert priority ranking correct (foundational + high-weight sections)
- [ ] Implement Test Case 5: Priorities Questionnaire (AC: 6)
  - [ ] Submit priorities via POST /assessments/:id/priorities
  - [ ] Assert 201 response and AssessmentPriorities record created
  - [ ] Retrieve priorities via GET /assessments/:id/priorities
  - [ ] Assert data matches submission
  - [ ] Test validation: rankedPriorities subset of selectedUseCases
- [ ] Implement Test Case 6: Enhanced Vendor Matching (AC: 7)
  - [ ] Seed vendor database with 10 test vendors
  - [ ] Request vendor matches via GET /assessments/:id/vendor-matches-v2
  - [ ] Assert vendors scored with base + boost
  - [ ] Assert match reasons generated for each vendor
  - [ ] Assert vendors sorted by totalScore descending
  - [ ] Assert only vendors with score ≥80 returned
- [ ] Implement Test Case 7: Strategy Matrix (AC: 8)
  - [ ] Request strategy matrix via GET /assessments/:id/strategy-matrix
  - [ ] Assert gaps organized into 3 timeline buckets
  - [ ] Assert bucket aggregations (gap count, effort, cost) correct
  - [ ] Assert vendor recommendations per bucket present
- [ ] Implement Test Case 8: Enhanced Results (AC: 9)
  - [ ] Request results via GET /assessments/:id/results
  - [ ] Assert evidence tier summary present
  - [ ] Assert weighted score breakdown present
  - [ ] Assert strategy matrix summary present
- [ ] Implement Test Case 9: Feature Flag Disabled (AC: 10)
  - [ ] Disable feature flag
  - [ ] Create assessment via API
  - [ ] Assert scoringMethodology = "unavailable"
  - [ ] Assert POST /priorities returns 400 error
  - [ ] Assert GET /vendor-matches-v2 returns 400 error
  - [ ] Assert GET /results excludes enhanced fields
- [ ] Implement Test Case 10: Legacy Compatibility (AC: 11)
  - [ ] Seed database with legacy assessment (methodology=null)
  - [ ] Query legacy assessment via API
  - [ ] Assert no errors or data corruption
  - [ ] Assert legacy results endpoint works

## Dev Notes

### Relevant Source Tree
- `backend/tests/integration/enhanced-assessment-e2e.spec.ts` - New E2E test suite (create new file)
- `backend/tests/setup.ts` - Test database initialization (existing)
- `backend/tests/helpers/` - Test data seeding helpers (create if needed)
- `backend/src/services/assessment.service.ts` - Assessment orchestration (60KB)
- `backend/src/services/weighted-scoring.service.ts` - Weighted scoring logic (Story 1.4)
- `backend/src/services/evidence-classification.service.ts` - Evidence classification (Story 1.3)
- `backend/src/services/priorities.service.ts` - Priorities management (Story 1.9)
- `backend/src/services/vendor-matching.service.ts` - Enhanced vendor matching (Story 1.13)
- `backend/src/services/strategy-matrix.service.ts` - Strategy matrix generation (Story 1.15)
- `backend/src/routes/assessment.routes.ts` - Assessment API endpoints (72KB)

### Testing Infrastructure

**Existing Test Framework:**
- Vitest 3 for test execution
- Real PostgreSQL test database
- Fastify inject for API testing without HTTP overhead
- Prisma test client for database operations

**Test Database Setup:**
Tests use a separate test database configured in `backend/tests/setup.ts`. Each test suite gets a clean database state via:
1. Prisma migration to latest schema
2. Seed minimal required data (templates, users)
3. Clean up after test completion

**Test Organization:**
- Contract tests: `backend/tests/contract/` - API specification compliance
- Integration tests: `backend/tests/integration/` - Real database integration
- This story adds: `backend/tests/integration/enhanced-assessment-e2e.spec.ts`

**Mocking Strategy:**
- **Do NOT mock**: Prisma client, database, internal services
- **Do mock**: External APIs (OpenAI, Stripe, AWS S3)
- **Use real data**: Create real test records in database
- **Reason**: Integration tests verify actual service integration, not unit behavior

**Test Data Seeding Helpers:**
Create helper functions for common test data:
```typescript
async function createTestAssessmentTemplate(prisma: PrismaClient): Promise<Template>
async function createTestUser(prisma: PrismaClient): Promise<User>
async function createTestOrganization(prisma: PrismaClient): Promise<Organization>
async function seedTestVendors(prisma: PrismaClient, count: number): Promise<Vendor[]>
```

### Integration Test Best Practices

**Arrange-Act-Assert Pattern:**
All tests follow AAA structure:
1. **Arrange**: Set up test data, enable feature flags, seed database
2. **Act**: Execute the API call or service method
3. **Assert**: Verify results match expectations

**Test Isolation:**
Each test case should be independent and not rely on state from previous tests. Use `beforeEach` to reset database state.

**Real API Calls:**
Use Fastify inject to make real API calls to routes:
```typescript
const response = await app.inject({
  method: 'POST',
  url: '/api/assessments',
  headers: { authorization: `Bearer ${token}` },
  payload: { templateId: template.id }
});
```

**Error Case Testing:**
Test both happy path and error cases:
- Valid data should succeed
- Invalid data should return appropriate error codes (400, 401, 404, etc.)
- Feature flag disabled should return 400 for enhanced endpoints

**Performance Assertions:**
Where performance is critical (NFR requirements), add timing assertions:
```typescript
const start = Date.now();
await completeAssessment(assessmentId);
const duration = Date.now() - start;
expect(duration).toBeLessThan(3000); // <3s requirement
```

### Integration Points

**Services Being Tested:**
This E2E test suite verifies the integration of 6+ services:
1. assessment.service.ts - Assessment lifecycle
2. evidence-classification.service.ts - Document tier classification
3. weighted-scoring.service.ts - Score calculations
4. priorities.service.ts - Priorities questionnaire
5. vendor-matching.service.ts - Enhanced vendor matching
6. strategy-matrix.service.ts - Timeline bucketing

**API Endpoints Being Tested:**
- POST /api/assessments - Create assessment
- POST /api/assessments/:id/documents - Upload documents
- POST /api/assessments/:id/complete - Complete assessment
- GET /api/assessments/:id/results - Retrieve results
- POST /api/assessments/:id/priorities - Submit priorities
- GET /api/assessments/:id/priorities - Retrieve priorities
- GET /api/assessments/:id/vendor-matches-v2 - Enhanced vendor matching
- GET /api/assessments/:id/strategy-matrix - Strategy matrix

**Feature Flags:**
Tests must manipulate ENHANCED_SCORING_ENABLED environment variable to test both enabled and disabled scenarios.

### Testing

**Location:** `backend/tests/integration/enhanced-assessment-e2e.spec.ts`

**Testing Frameworks:**
- Vitest 3 for test execution
- Fastify inject for API testing
- Prisma test client for database operations
- chai/expect for assertions

**Test Execution:**
```bash
# Run all integration tests
npm run test:integration

# Run only E2E test suite
npm run test:integration -- enhanced-assessment-e2e

# Run with coverage
npm run test:integration -- --coverage
```

**Coverage Target:**
- ≥90% coverage of critical paths (assessment lifecycle, scoring, vendor matching)
- All 11 test cases must pass

**CI Integration:**
E2E tests run automatically on every commit via GitHub Actions workflow (`.github/workflows/ci.yml`). Tests must pass before merge to main.

**Test Duration:**
Full E2E test suite should complete within 60 seconds. Individual test cases should complete within 10 seconds each.

## Change Log

| Date       | Version | Description                          | Author        |
|------------|---------|--------------------------------------|---------------|
| 2025-10-07 | 1.0     | Initial story created from PRD Epic 1 | SM (Winston)  |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent during implementation_

### Debug Log References
_To be populated by dev agent during implementation_

### Completion Notes
_To be populated by dev agent during implementation_

### File List
_To be populated by dev agent during implementation_

## QA Results

_To be populated by QA agent after implementation review_
