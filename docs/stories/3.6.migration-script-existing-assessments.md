# Story 3.6: Migration Script for Existing Assessments

## Status
Draft

## Story

**As a** DevOps engineer,
**I want** to generate AI content for existing assessments,
**So that** all completed assessments have AI insights

## Acceptance Criteria

1. Script identifies completed assessments without AI content
2. Processes in batches of 10 with 1-second delay (rate limiting)
3. Logs progress with success/failure counts
4. Can be safely re-run (idempotent - skips already processed)
5. Does NOT modify any existing data except new AI columns
6. Dry-run mode for testing
7. Estimated completion time calculated and displayed
8. Failed assessments logged for manual review

## Tasks / Subtasks

- [ ] Task 1: Create migration script file (AC: 1)
  - [ ] Create `backend/prisma/generate-ai-analysis.ts`
  - [ ] Import necessary dependencies (Prisma, AssessmentService)
  - [ ] Set up basic script structure with error handling
  - [ ] Add npm script to package.json

- [ ] Task 2: Implement assessment identification logic (AC: 1, 4)
  - [ ] Query for assessments with status COMPLETED
  - [ ] Filter for assessments where aiRiskAnalysis is null
  - [ ] Count total assessments needing processing
  - [ ] Log findings to console

- [ ] Task 3: Implement batch processing (AC: 2)
  - [ ] Process assessments in batches of 10
  - [ ] Add 1-second delay between batches
  - [ ] Implement rate limiting to prevent OpenAI overload
  - [ ] Show progress indicator

- [ ] Task 4: Add progress logging (AC: 3)
  - [ ] Log start of processing with total count
  - [ ] Log each assessment being processed
  - [ ] Track success and failure counts
  - [ ] Display running totals

- [ ] Task 5: Implement dry-run mode (AC: 6)
  - [ ] Add --dry-run command line flag
  - [ ] Skip actual generation in dry-run mode
  - [ ] Log what would be processed
  - [ ] Show estimated time and cost

- [ ] Task 6: Calculate time estimates (AC: 7)
  - [ ] Calculate based on batch size and delays
  - [ ] Show estimated completion time
  - [ ] Update estimate as processing proceeds
  - [ ] Display in human-readable format

- [ ] Task 7: Handle and log failures (AC: 8)
  - [ ] Catch errors for individual assessments
  - [ ] Continue processing after failures
  - [ ] Log failed assessment IDs to file
  - [ ] Provide summary at end

- [ ] Task 8: Ensure data safety (AC: 5)
  - [ ] Only update AI-related columns
  - [ ] Use specific update queries (not full assessment update)
  - [ ] Add transaction safety where appropriate
  - [ ] Test on staging first

## Dev Notes

### Script Location and Structure

Create file at: `backend/prisma/generate-ai-analysis.ts`

```typescript
#!/usr/bin/env tsx

import { PrismaClient, AssessmentStatus } from '@prisma/client';
import { AssessmentService } from '../src/services/assessment.service';
import { parseArgs } from 'util';

// Parse command line arguments
const { values } = parseArgs({
  args: process.argv.slice(2),
  options: {
    'dry-run': {
      type: 'boolean',
      default: false
    },
    'batch-size': {
      type: 'string',
      default: '10'
    }
  }
});

const isDryRun = values['dry-run'];
const batchSize = parseInt(values['batch-size'] as string, 10);

const prisma = new PrismaClient();
const assessmentService = new AssessmentService();

async function main() {
  console.log('🤖 AI Analysis Generation Script');
  console.log('=================================');

  if (isDryRun) {
    console.log('🔍 DRY RUN MODE - No changes will be made');
  }

  try {
    // Find assessments needing AI analysis
    const assessments = await prisma.assessment.findMany({
      where: {
        status: AssessmentStatus.COMPLETED,
        aiRiskAnalysis: null
      },
      select: {
        id: true,
        organizationId: true,
        createdAt: true
      },
      orderBy: {
        createdAt: 'asc' // Process oldest first
      }
    });

    if (assessments.length === 0) {
      console.log('✅ All completed assessments already have AI analysis');
      return;
    }

    console.log(`📊 Found ${assessments.length} assessments needing AI analysis`);

    // Calculate estimates
    const totalBatches = Math.ceil(assessments.length / batchSize);
    const estimatedSeconds = (assessments.length * 3) + (totalBatches * 1);
    const estimatedMinutes = Math.ceil(estimatedSeconds / 60);
    const estimatedCost = assessments.length * 0.005;

    console.log(`⏱️  Estimated time: ${estimatedMinutes} minutes`);
    console.log(`💰 Estimated cost: $${estimatedCost.toFixed(2)}`);

    if (isDryRun) {
      console.log('\n📝 Would process the following assessments:');
      assessments.slice(0, 5).forEach(a => {
        console.log(`  - ${a.id} (created: ${a.createdAt.toLocaleDateString()})`);
      });
      if (assessments.length > 5) {
        console.log(`  ... and ${assessments.length - 5} more`);
      }
      return;
    }

    // Process assessments
    const results = {
      success: 0,
      failed: 0,
      failedIds: [] as string[]
    };

    const startTime = Date.now();

    for (let i = 0; i < assessments.length; i += batchSize) {
      const batch = assessments.slice(i, i + batchSize);
      const batchNum = Math.floor(i / batchSize) + 1;

      console.log(`\n📦 Processing batch ${batchNum}/${totalBatches}`);

      const batchPromises = batch.map(async (assessment) => {
        try {
          console.log(`  ⚙️  Processing ${assessment.id}...`);

          const result = await assessmentService.generateAndStoreAIAnalysis(
            assessment.id
          );

          if (result.success) {
            console.log(`  ✅ ${assessment.id} - Success`);
            results.success++;
          } else {
            console.log(`  ❌ ${assessment.id} - Failed: ${result.error}`);
            results.failed++;
            results.failedIds.push(assessment.id);
          }
        } catch (error) {
          console.error(`  ❌ ${assessment.id} - Error:`, error);
          results.failed++;
          results.failedIds.push(assessment.id);
        }
      });

      await Promise.all(batchPromises);

      // Progress update
      const processed = Math.min(i + batchSize, assessments.length);
      const percentage = Math.round((processed / assessments.length) * 100);
      const elapsed = Math.round((Date.now() - startTime) / 1000);
      const remaining = Math.round((estimatedSeconds - elapsed) / 60);

      console.log(`\n📊 Progress: ${processed}/${assessments.length} (${percentage}%)`);
      console.log(`⏱️  Elapsed: ${elapsed}s | Remaining: ~${remaining} minutes`);
      console.log(`✅ Success: ${results.success} | ❌ Failed: ${results.failed}`);

      // Rate limiting delay between batches
      if (i + batchSize < assessments.length) {
        console.log('⏳ Waiting 1 second before next batch...');
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }

    // Final summary
    console.log('\n' + '='.repeat(50));
    console.log('✨ Migration Complete!');
    console.log(`  ✅ Successfully processed: ${results.success}`);
    console.log(`  ❌ Failed: ${results.failed}`);

    if (results.failedIds.length > 0) {
      // Write failed IDs to file
      const fs = await import('fs/promises');
      const failedFile = `failed-assessments-${Date.now()}.json`;
      await fs.writeFile(
        failedFile,
        JSON.stringify(results.failedIds, null, 2)
      );
      console.log(`  📝 Failed IDs saved to: ${failedFile}`);
    }

    const totalTime = Math.round((Date.now() - startTime) / 1000 / 60);
    console.log(`  ⏱️  Total time: ${totalTime} minutes`);

  } catch (error) {
    console.error('❌ Script failed:', error);
    process.exit(1);
  } finally {
    await prisma.$disconnect();
  }
}

// Run the script
main().catch((error) => {
  console.error('Fatal error:', error);
  process.exit(1);
});
```

### Package.json Script

Add to `backend/package.json`:
```json
{
  "scripts": {
    // ... existing scripts ...
    "db:generate-ai-analysis": "tsx prisma/generate-ai-analysis.ts",
    "db:generate-ai-analysis:dry": "tsx prisma/generate-ai-analysis.ts --dry-run"
  }
}
```

### Usage Examples

```bash
# Dry run to see what would be processed
npm run db:generate-ai-analysis:dry

# Run with default settings (batch size 10)
npm run db:generate-ai-analysis

# Run with custom batch size
npm run db:generate-ai-analysis -- --batch-size=5

# Run in production
NODE_ENV=production npm run db:generate-ai-analysis
```

### Progress Output Example

```
🤖 AI Analysis Generation Script
=================================
📊 Found 47 assessments needing AI analysis
⏱️  Estimated time: 3 minutes
💰 Estimated cost: $0.24

📦 Processing batch 1/5
  ⚙️  Processing cmgtbfhvx0009lvmynuk2uds3...
  ✅ cmgtbfhvx0009lvmynuk2uds3 - Success
  ⚙️  Processing cmgtfhtuq0001lcej759yjqrs...
  ✅ cmgtfhtuq0001lcej759yjqrs - Success

📊 Progress: 10/47 (21%)
⏱️  Elapsed: 32s | Remaining: ~2 minutes
✅ Success: 10 | ❌ Failed: 0
⏳ Waiting 1 second before next batch...
```

### Error Handling

Individual assessment failures don't stop the entire migration:
```typescript
// Continue processing even if one fails
try {
  await generateForAssessment(id);
} catch (error) {
  logError(id, error);
  continue; // Move to next assessment
}
```

### Safety Checks

The script only modifies the new AI columns added in Story 3.1:
```typescript
// Service method only updates specific fields
await prisma.assessment.update({
  where: { id },
  data: {
    aiRiskAnalysis: analysis,      // New column
    aiStrategyMatrix: matrix,       // New column
    aiGeneratedAt: new Date()       // New column
    // No other fields are touched
  }
});
```

### Monitoring Recommendations

```typescript
// Add optional Slack/email notification
if (process.env.SLACK_WEBHOOK) {
  await notifySlack({
    text: `AI Analysis Migration Complete: ${results.success} success, ${results.failed} failed`
  });
}
```

### Testing Approach

1. **Test on staging first** with a small subset
2. **Verify idempotency** by running twice
3. **Check failed assessments** can be retried
4. **Monitor OpenAI API usage** during migration

## Testing

### Testing Standards

**Test File Location:**
`backend/prisma/generate-ai-analysis.test.ts`

**Test Scenarios:**
```typescript
import { describe, it, expect, beforeAll, vi } from 'vitest';
import { execSync } from 'child_process';

describe('AI Analysis Migration Script', () => {
  it('should identify assessments without AI analysis', async () => {
    const output = execSync(
      'npm run db:generate-ai-analysis:dry',
      { encoding: 'utf-8' }
    );

    expect(output).toContain('Found');
    expect(output).toContain('assessments needing AI analysis');
  });

  it('should skip already processed assessments', async () => {
    // Run twice to test idempotency
    execSync('npm run db:generate-ai-analysis -- --batch-size=1');
    const output = execSync(
      'npm run db:generate-ai-analysis:dry',
      { encoding: 'utf-8' }
    );

    expect(output).toContain('already have AI analysis');
  });

  it('should handle errors gracefully', async () => {
    // Mock a failure
    vi.spyOn(assessmentService, 'generateAndStoreAIAnalysis')
      .mockRejectedValueOnce(new Error('API Error'));

    const output = execSync(
      'npm run db:generate-ai-analysis -- --batch-size=1',
      { encoding: 'utf-8' }
    );

    expect(output).toContain('Failed: 1');
    expect(output).toContain('failed-assessments');
  });
});
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-21 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent_

### Debug Log References
_To be populated by dev agent_

### Completion Notes List
_To be populated by dev agent_

### File List
_To be populated by dev agent_

## QA Results
_To be populated by QA agent_