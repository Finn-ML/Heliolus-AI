# Story 1.24: Performance Optimization and Caching Strategy

## Status
Draft

## Story

**As a** backend developer,
**I want** to implement aggressive caching and query optimization for enhanced assessment features,
**so that** the system maintains sub-3-second response times despite increased computational complexity.

## Acceptance Criteria

1. **Redis Caching for Evidence Classification:**
   - Cache key pattern: `evidence_classification:<document_id>`
   - TTL: 30 days
   - Cache stores: `{ tier, confidence, reason, classifiedAt }`
   - Before classifying document, check cache
   - After classification, store in cache
   - Cache invalidation: when document deleted or admin overrides tier
2. **Redis Caching for Vendor Matches:**
   - Cache key pattern: `vendor_matches:v2:<priorities_hash>`
   - Priorities hash: SHA-256 of AssessmentPriorities data (consistent hashing for same priorities)
   - TTL: 24 hours
   - Cache stores: full vendor match results array with scores and reasoning
   - Cache invalidation: when vendor database updated (manual admin trigger)
3. **Redis Caching for Strategy Matrix:**
   - Cache key pattern: `strategy_matrix:<assessment_id>`
   - TTL: 7 days
   - Cache stores: full matrix with gaps organized by bucket
   - Cache invalidation: when assessment updated or gaps modified
4. **Memoization for Weighted Score Calculations:**
   - Use in-memory memoization for repeated score calculations during same request
   - Cache question scores, section scores during overall score calculation
   - Reset memoization cache per request (don't leak across requests)
5. **Database Query Optimization:**
   - Add database indexes:
     - `assessments (scoringMethodology)` - filter by methodology
     - `documents (evidenceTier, tierConfidenceScore)` - admin review query
     - `gaps (assessmentId, priority)` - strategy matrix bucketing
     - `vendorMatches (assessmentId, totalScore)` - sorted vendor retrieval
   - Use Prisma `select` to limit fields returned (don't fetch unnecessary JSON blobs)
   - Use Prisma `include` efficiently (batch load related records, avoid N+1 queries)
6. **Async Background Processing:**
   - Evidence classification runs in background job (don't block assessment completion)
   - Use job queue (Bull with Redis backend)
   - Frontend polls for classification completion
   - Job retry logic: 3 retries with exponential backoff
7. **Response Pagination:**
   - Vendor matches: paginate if >50 vendors (return first 50, provide "load more")
   - Gap list: paginate if >100 gaps
   - Admin evidence review: paginate 20 documents per page
8. **Performance Monitoring:**
   - Add custom metrics for:
     - `evidence_classification_cache_hit_rate` (gauge)
     - `vendor_matching_cache_hit_rate` (gauge)
     - `strategy_matrix_cache_hit_rate` (gauge)
     - `weighted_scoring_duration_ms` (histogram)
     - `api_response_time_ms` (histogram, per endpoint)
   - Metrics exposed via /metrics endpoint (Prometheus format)
9. **Performance Benchmarks:**
   - Assessment results page: <3 seconds (50 questions, 20 documents)
   - Vendor matching: <2 seconds (100 vendors in database)
   - Evidence classification: <5 seconds per document
   - Strategy matrix generation: <1 second
10. **Load Testing:**
    - Simulate 50 concurrent users creating/completing assessments
    - System maintains response times within benchmarks under load
    - No memory leaks after 1000 requests

## Tasks / Subtasks

- [ ] Implement Redis caching for evidence classification (AC: 1)
  - [ ] Add cache check before classification in evidence-classification.service.ts
  - [ ] Store classification result in Redis after AI classification
  - [ ] Use key pattern: `evidence_classification:<document_id>`
  - [ ] Set TTL to 30 days (2592000 seconds)
  - [ ] Implement cache invalidation on document delete
  - [ ] Implement cache invalidation on admin tier override
- [ ] Implement Redis caching for vendor matches (AC: 2)
  - [ ] Create hash function for AssessmentPriorities data (SHA-256)
  - [ ] Check cache before running vendor matching algorithm
  - [ ] Store vendor match results in Redis after calculation
  - [ ] Use key pattern: `vendor_matches:v2:<priorities_hash>`
  - [ ] Set TTL to 24 hours (86400 seconds)
  - [ ] Add admin endpoint to manually invalidate vendor match cache
- [ ] Implement Redis caching for strategy matrix (AC: 3)
  - [ ] Check cache before generating strategy matrix
  - [ ] Store strategy matrix result in Redis after calculation
  - [ ] Use key pattern: `strategy_matrix:<assessment_id>`
  - [ ] Set TTL to 7 days (604800 seconds)
  - [ ] Implement cache invalidation on assessment update
  - [ ] Implement cache invalidation on gap modification
- [ ] Implement in-memory memoization for weighted scoring (AC: 4)
  - [ ] Add memoization utility function with WeakMap
  - [ ] Memoize question score calculations
  - [ ] Memoize section score calculations
  - [ ] Ensure memoization cache scoped to single request
  - [ ] Add cache clearing after request completes
- [ ] Add database indexes for performance (AC: 5)
  - [ ] Create migration adding index on assessments(scoringMethodology)
  - [ ] Create migration adding composite index on documents(evidenceTier, tierConfidenceScore)
  - [ ] Create migration adding composite index on gaps(assessmentId, priority)
  - [ ] Create migration adding composite index on vendorMatches(assessmentId, totalScore)
  - [ ] Test query performance before and after indexes
- [ ] Optimize Prisma queries (AC: 5)
  - [ ] Audit all assessment.service.ts queries for unnecessary field fetching
  - [ ] Add `select` clauses to limit returned fields
  - [ ] Replace N+1 queries with `include` batching
  - [ ] Test query performance with EXPLAIN ANALYZE
- [ ] Implement async background processing for classification (AC: 6)
  - [ ] Install Bull job queue library (npm install bull)
  - [ ] Create job queue: `evidence-classification-queue`
  - [ ] Move classification logic to background job
  - [ ] Add job retry logic: 3 retries with exponential backoff (2s, 4s, 8s)
  - [ ] Add frontend polling endpoint: GET /documents/:id/classification-status
- [ ] Implement response pagination (AC: 7)
  - [ ] Add pagination to GET /vendor-matches-v2 (limit 50, cursor-based)
  - [ ] Add pagination to GET /gaps (limit 100, offset-based)
  - [ ] Add pagination to GET /admin/evidence-classification/review (limit 20, offset-based)
  - [ ] Include pagination metadata in responses (total, page, hasMore)
- [ ] Add performance monitoring metrics (AC: 8)
  - [ ] Install prom-client (npm install prom-client)
  - [ ] Create metrics registry
  - [ ] Add cache hit rate gauges for 3 cache types
  - [ ] Add duration histograms for scoring and API endpoints
  - [ ] Expose metrics via GET /metrics endpoint
  - [ ] Add middleware to track API response times
- [ ] Run performance benchmarks (AC: 9)
  - [ ] Create benchmark script: backend/scripts/performance-benchmark.ts
  - [ ] Benchmark assessment results page (<3s target)
  - [ ] Benchmark vendor matching (<2s target)
  - [ ] Benchmark evidence classification (<5s target)
  - [ ] Benchmark strategy matrix generation (<1s target)
  - [ ] Document results in performance-report.md
- [ ] Run load testing (AC: 10)
  - [ ] Install artillery or k6 for load testing
  - [ ] Create load test scenario: 50 concurrent users
  - [ ] Run load test for 10 minutes
  - [ ] Monitor response times, error rates, memory usage
  - [ ] Verify no memory leaks after 1000 requests
  - [ ] Document results in load-test-report.md

## Dev Notes

### Relevant Source Tree
- `backend/src/services/evidence-classification.service.ts` - Add Redis caching (Story 1.3)
- `backend/src/services/vendor-matching.service.ts` - Add Redis caching (Story 1.13)
- `backend/src/services/strategy-matrix.service.ts` - Add Redis caching (Story 1.15)
- `backend/src/services/weighted-scoring.service.ts` - Add memoization (Story 1.4)
- `backend/src/lib/cache.ts` - Create caching utility (new file)
- `backend/src/lib/metrics.ts` - Create metrics utility (new file)
- `backend/src/lib/job-queue.ts` - Create job queue utility (new file)
- `backend/prisma/migrations/` - Add performance indexes
- `backend/scripts/performance-benchmark.ts` - Benchmark script (new file)
- `backend/scripts/load-test.yml` - Load test configuration (new file)

### Caching Strategy

**Existing Redis Infrastructure:**
The platform already uses ioredis 5.x for caching. Redis is running on port 6379 in Docker Compose. Existing pattern from architecture review shows Redis is used for session data and rate limiting.

**Redis Key Naming Convention:**
- Use descriptive prefixes for easy cache management
- Include version number for cache schema changes: `v1:evidence_classification:<id>`
- Use colons as separators for hierarchy: `namespace:category:identifier`

**Cache Key Patterns:**
1. **Evidence Classification**: `v1:evidence_classification:<document_id>`
   - Stores: `{ tier: "TIER_2", confidence: 0.95, reason: "...", classifiedAt: "2025-10-07T..." }`
   - TTL: 30 days (classification rarely changes)
   - Invalidation: Document delete, admin override

2. **Vendor Matches**: `v1:vendor_matches:v2:<priorities_hash>`
   - Priorities hash: SHA-256 of serialized AssessmentPriorities data
   - Stores: Full vendor match array with scores and reasoning
   - TTL: 24 hours (vendor data may update)
   - Invalidation: Vendor database update, manual admin trigger

3. **Strategy Matrix**: `v1:strategy_matrix:<assessment_id>`
   - Stores: Full matrix with timeline buckets and gap organization
   - TTL: 7 days (assessment unlikely to change after completion)
   - Invalidation: Assessment update, gap modification

**Cache-Aside Pattern:**
All caches use cache-aside (lazy loading):
1. Check cache first
2. If hit: return cached value
3. If miss: compute value, store in cache, return value

**Cache Invalidation Strategy:**
- **Time-based**: TTL expires, cache auto-invalidates
- **Event-based**: Explicit invalidation on data modification (delete, update)
- **Manual**: Admin trigger for vendor database updates

**Redis Client Reuse:**
Reuse existing Redis client from `backend/src/config/redis.ts` (or create if doesn't exist). Do NOT create new Redis connections per request.

### Memoization Strategy

**Request-Scoped Memoization:**
Use WeakMap for automatic garbage collection:
```typescript
const memoCache = new WeakMap<Request, Map<string, any>>();
```

**Memoization Utility:**
```typescript
function memoize<T>(req: Request, key: string, fn: () => T): T {
  if (!memoCache.has(req)) memoCache.set(req, new Map());
  const cache = memoCache.get(req)!;
  if (!cache.has(key)) cache.set(key, fn());
  return cache.get(key);
}
```

**Use Cases:**
- Question score calculation (called multiple times during section scoring)
- Section score calculation (called multiple times during overall scoring)
- Document tier lookup (called multiple times during answer scoring)

**Cache Lifetime:**
Memoization cache lives only for duration of single request. Fastify request lifecycle automatically cleans up WeakMap entries.

### Database Optimization

**Index Strategy:**
Add indexes to support common query patterns:
1. `assessments (scoringMethodology)` - Filter enhanced vs legacy assessments
2. `documents (evidenceTier, tierConfidenceScore)` - Admin review query sorts by confidence
3. `gaps (assessmentId, priority)` - Strategy matrix groups by assessment and sorts by priority
4. `vendorMatches (assessmentId, totalScore)` - Sorted vendor retrieval for results page

**Prisma Query Optimization:**
- Use `select` to avoid fetching large JSON fields unnecessarily
- Use `include` with specific relations to batch load (avoid N+1)
- Use `take` and `skip` for pagination
- Use `orderBy` with indexed columns

**Query Performance Testing:**
Use Prisma query logging to identify slow queries:
```typescript
// In prisma client config
log: ['query', 'info', 'warn', 'error']
```

Analyze queries with PostgreSQL EXPLAIN ANALYZE:
```sql
EXPLAIN ANALYZE SELECT * FROM assessments WHERE scoringMethodology = 'complete';
```

### Background Job Processing

**Bull Job Queue:**
Install Bull for reliable background job processing with Redis backend:
```bash
npm install bull @types/bull
```

**Job Queue Configuration:**
```typescript
const classificationQueue = new Bull('evidence-classification', {
  redis: { host: 'localhost', port: 6379 },
  defaultJobOptions: {
    attempts: 3,
    backoff: { type: 'exponential', delay: 2000 }
  }
});
```

**Job Lifecycle:**
1. User uploads document
2. API returns 202 Accepted with job ID
3. Job added to queue
4. Worker processes classification (async)
5. Frontend polls GET /documents/:id/classification-status
6. When complete, frontend updates UI

**Job Retry Logic:**
- Attempt 1: Immediate
- Attempt 2: 2 seconds delay
- Attempt 3: 4 seconds delay
- Attempt 4: 8 seconds delay
- After 3 retries: Mark job as failed, notify admin

### Performance Monitoring

**Prometheus Metrics:**
Use prom-client library to expose metrics in Prometheus format:
```bash
npm install prom-client
```

**Metrics to Track:**
1. **Cache Hit Rates** (Gauge):
   - evidence_classification_cache_hit_rate
   - vendor_matching_cache_hit_rate
   - strategy_matrix_cache_hit_rate

2. **Duration Histograms** (Histogram):
   - weighted_scoring_duration_ms (buckets: 10, 50, 100, 500, 1000, 5000)
   - api_response_time_ms (buckets: 10, 50, 100, 500, 1000, 3000, 5000)

3. **Request Counters** (Counter):
   - http_requests_total (labels: method, route, status)
   - background_jobs_total (labels: queue, status)

**Metrics Endpoint:**
Expose metrics at GET /metrics for Prometheus scraping:
```typescript
app.get('/metrics', async (req, res) => {
  res.type('text/plain');
  res.send(await register.metrics());
});
```

**Monitoring Dashboard:**
Metrics can be visualized in Grafana (future work, not in this story).

### Integration Points

**Services Requiring Optimization:**
- evidence-classification.service.ts - Add Redis caching, background job
- vendor-matching.service.ts - Add Redis caching
- strategy-matrix.service.ts - Add Redis caching
- weighted-scoring.service.ts - Add in-memory memoization
- assessment.service.ts - Optimize Prisma queries

**API Endpoints Requiring Pagination:**
- GET /api/assessments/:id/vendor-matches-v2 - Paginate if >50 vendors
- GET /api/assessments/:id/gaps - Paginate if >100 gaps
- GET /api/admin/evidence-classification/review - Paginate 20 per page

**Infrastructure Dependencies:**
- Redis 7 (existing) - Caching backend
- PostgreSQL 15 (existing) - Add indexes
- Bull (new) - Background job queue

### Testing

**Location:** `backend/tests/integration/performance-optimization.spec.ts` and `backend/scripts/performance-benchmark.ts`

**Testing Frameworks:**
- Vitest 3 for integration tests
- Artillery or k6 for load testing
- Prisma for database query testing

**Test Cases:**

**Integration Tests:**
1. Evidence classification cache hit/miss behavior
   - First call: cache miss, AI called
   - Second call: cache hit, AI not called
2. Cache invalidation on document delete
3. Cache invalidation on admin override
4. Vendor matches cache with same priorities returns cached result
5. Vendor matches cache with different priorities computes new result
6. Strategy matrix cache hit/miss behavior
7. Memoization cache scoped to single request
8. Pagination returns correct page size and metadata
9. Background job processes classification successfully
10. Background job retries on failure with exponential backoff

**Performance Benchmarks:**
1. Assessment results page load time (target: <3s)
   - Create assessment with 50 questions, 20 documents
   - Measure time from request to response
2. Vendor matching computation time (target: <2s)
   - Seed database with 100 vendors
   - Measure time from request to response
3. Evidence classification time (target: <5s per document)
   - Upload document
   - Measure time from upload to classification complete
4. Strategy matrix generation time (target: <1s)
   - Assessment with 30 gaps
   - Measure time from request to response

**Load Tests:**
1. 50 concurrent users creating assessments
   - Ramp up over 30 seconds
   - Sustain for 10 minutes
   - Ramp down over 30 seconds
2. Verify response times stay within benchmarks under load
3. Verify no 500 errors
4. Verify no memory leaks (memory usage returns to baseline after test)

**Coverage Target:** ≥80% code coverage for caching utility functions

**CI Integration:**
- Performance benchmarks run on every commit (GitHub Actions)
- Benchmarks must pass within 10% of target times
- Load tests run nightly or on release branches

## Change Log

| Date       | Version | Description                          | Author        |
|------------|---------|--------------------------------------|---------------|
| 2025-10-07 | 1.0     | Initial story created from PRD Epic 1 | SM (Winston)  |

## Dev Agent Record

### Agent Model Used
_To be populated by dev agent during implementation_

### Debug Log References
_To be populated by dev agent during implementation_

### Completion Notes
_To be populated by dev agent during implementation_

### File List
_To be populated by dev agent during implementation_

## QA Results

_To be populated by QA agent after implementation review_
